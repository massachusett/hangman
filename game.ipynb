{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string  \n",
    "import re\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word set\n",
    "word_path = './words.txt'\n",
    "word_file = open(word_path, 'r')\n",
    "words = word_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Words in Dataset: 227300\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Number of Words in Dataset: {len(words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean word set by removing whitespace, converting to lowercase, removing duplicates, and removing words with numbers\n",
    "words = [w.strip('\\n').lower() for w in words]\n",
    "words = list(set(words))\n",
    "words = [w for w in words if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Words in Dataset After Cleaning: 227300\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Number of Words in Dataset After Cleaning: {len(words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split word set into training and validation\n",
    "train_idx = np.random.choice(len(words), len(words) // 2, replace=False)\n",
    "val_idx = np.array(list(set(range(len(words))) - set(train_idx)))\n",
    "\n",
    "train_words = list(np.array(words)[train_idx])\n",
    "val_words = list(np.array(words)[val_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Words in Training Dataset: 113650\n",
      "Total Number of Words in Training Dataset: 113650\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Number of Words in Training Dataset: {len(train_words)}')\n",
    "print(f'Total Number of Words in Training Dataset: {len(val_words)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter2index(letter):\n",
    "    return ord(letter) - ord('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index2letter(ind):\n",
    "    return chr(ind + ord('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HangmanGame():\n",
    "    \n",
    "    def __init__(self, corpus, N_LIVES=6):\n",
    "\n",
    "        self.corpus = corpus\n",
    "        self.N_LIVES = N_LIVES\n",
    "\n",
    "    def word2info(self):\n",
    "\n",
    "        info = []\n",
    "\n",
    "        for letter in self.word:\n",
    "            if letter in self.guessed:\n",
    "                info.append(letter)\n",
    "            else:\n",
    "                info.append('_')\n",
    "\n",
    "        return info\n",
    "\n",
    "    def start(self, verbose=False):\n",
    "\n",
    "        self.word = np.random.choice(self.corpus, 1)[0]\n",
    "        self.unused = set(string.ascii_lowercase)\n",
    "        self.guessed = set()\n",
    "        self.info = self.word2info()\n",
    "        self.LIVES_LEFT = self.N_LIVES\n",
    "        self.ongoing = True\n",
    "        self.verbose = verbose\n",
    "\n",
    "        if self.verbose:\n",
    "            print(self.info)\n",
    "            print(f'LIVES LEFT: {self.LIVES_LEFT}')\n",
    "\n",
    "        return self.info\n",
    "\n",
    "    def guess(self, letter):\n",
    "\n",
    "        if not self.ongoing:\n",
    "            \n",
    "            if self.verbose:\n",
    "                print('The game is already over! Stop making guesses!')\n",
    "            return -2\n",
    "        \n",
    "        elif letter in self.guessed:\n",
    "            \n",
    "            if self.verbose:\n",
    "                print('You already guessed this letter! Try another letter!')\n",
    "            return 0\n",
    "        \n",
    "        else:\n",
    "\n",
    "            update_set = set([letter])\n",
    "            self.guessed.update(update_set)\n",
    "            self.unused = self.unused - update_set\n",
    "            self.info = self.word2info()\n",
    "\n",
    "            if letter not in self.word:\n",
    "                self.LIVES_LEFT -= 1\n",
    "\n",
    "            if self.LIVES_LEFT == 0:\n",
    "\n",
    "                if self.verbose:\n",
    "                    print(f'You lose! The word was {self.word}.')\n",
    "                return -1\n",
    "            elif ''.join(self.info) == self.word:\n",
    "                if self.verbose:\n",
    "                    print('You win!')\n",
    "                return 2\n",
    "            else:\n",
    "                if self.verbose:\n",
    "                    print(self.info)\n",
    "                    print(f'LIVES LEFT: {self.LIVES_LEFT}')\n",
    "                return self.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ngrams(corpus, n):\n",
    "\n",
    "    ngrams = np.zeros((26,) * n)\n",
    "\n",
    "    for word in corpus:\n",
    "        for i in range(0, len(word)-n+1):\n",
    "\n",
    "            indices = np.zeros(n, dtype='int')\n",
    "\n",
    "            for j in range(n):\n",
    "                indices[j] = letter2index(word[i+j])\n",
    "\n",
    "            indices = tuple(indices)\n",
    "\n",
    "            ngrams[indices] += 1\n",
    "            \n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_vec(vec, guessed, mask_val=0):\n",
    "\n",
    "    vec = vec.copy()\n",
    "\n",
    "    if len(guessed) > 0:\n",
    "\n",
    "        for letter in guessed:\n",
    "            vec[letter2index(letter)] = 0\n",
    "\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window(lst, index, width=1):\n",
    "\n",
    "    start_width = 0\n",
    "    for i in range(1, 2*width + 1):\n",
    "        if (index - i >= 0) and (lst[index - i] != '_'):\n",
    "            start_width += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    end_width = 0\n",
    "    for i in range(1, 2*width + 1):\n",
    "        if (index + i < len(lst)) and (lst[index + i] != '_'):\n",
    "            end_width += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if (end_width >= width) and (start_width >= width):\n",
    "        end_width = width\n",
    "        start_width = width\n",
    "    elif end_width < width:\n",
    "        start_width = min(2*width - end_width, start_width)\n",
    "    elif start_width < width:\n",
    "        end_width = min(2*width - start_width, end_width)\n",
    "\n",
    "    start = index - start_width\n",
    "    end = index + end_width\n",
    "\n",
    "    sublist = lst[start:end + 1]\n",
    "    new_index = index - start\n",
    "    return sublist, new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_guess(grams, info, guessed, max_width=1):\n",
    "\n",
    "    probs = np.zeros(26)\n",
    "\n",
    "    n = len(info)\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        if info[i] == '_':\n",
    "\n",
    "            window, center = get_window(info, i, width=max_width) \n",
    "            m = len(window)\n",
    "\n",
    "            vec = grams[m-1].copy()\n",
    "            sub = 0\n",
    "\n",
    "            for j in range(m):\n",
    "                if j != center:\n",
    "                    vec = np.take(vec, letter2index(window[j]), axis=j-sub)\n",
    "                    sub += 1               \n",
    "\n",
    "            vec = mask_vec(vec, guessed)\n",
    "\n",
    "            while vec.sum() == 0:\n",
    "\n",
    "                vec = mask_vec(grams[0], guessed)\n",
    "            \n",
    "            probs += vec / vec.sum()\n",
    "    \n",
    "    probs = mask_vec(probs, guessed, mask_val=-1)\n",
    "    return index2letter(np.argmax(probs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info2regex(info, unused):\n",
    "\n",
    "    regex = r'^'\n",
    "    unknown = rf'[{''.join(list(unused))}]'\n",
    "\n",
    "    for space in info:\n",
    "        if space == '_':\n",
    "            regex = regex + unknown\n",
    "        else:\n",
    "            regex = regex + rf'{space}'\n",
    "\n",
    "    regex = regex + r'$'\n",
    "\n",
    "    return regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = 'a e i o u'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vowel_percentage(word):\n",
    "    vowel_count = sum(1 for char in word if char in vowels)\n",
    "    total_letters = len(word)\n",
    "    if total_letters == 0:\n",
    "        percentage = 0\n",
    "    else:\n",
    "        percentage = (vowel_count / total_letters) * 100\n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Trials for Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIALS = 1000\n",
    "game = HangmanGame(val_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_grams = []\n",
    "max_width = 2\n",
    "    \n",
    "for i in range(1, 2*max_width + 2):\n",
    "    full_grams.append(count_ngrams(train_words, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49501dcc4fb496b868f402fb6dcaa6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for trial in tqdm(range(N_TRIALS)):\n",
    "\n",
    "    info = game.start()\n",
    "    win = False\n",
    "    unused = game.unused.copy()\n",
    "    guessed = game.guessed.copy()\n",
    "    unused_vowels = set(vowels)\n",
    "    n_lives = game.LIVES_LEFT\n",
    "    pattern = info2regex(info, unused)\n",
    "    matches = [word for word in train_words if re.fullmatch(pattern, word)]\n",
    "    subcorpus = matches.copy()\n",
    "\n",
    "    m = len(info)\n",
    "    vps = [vowel_percentage(word) for word in train_words if len(word) <= m]\n",
    "    threshold = np.quantile(np.array(vps), q=0.75)\n",
    "    \n",
    "    while (n_lives > 0) and (win == False):\n",
    "    \n",
    "        guess = make_guess(full_grams, info, guessed, max_width=max_width)\n",
    "\n",
    "        output = game.guess(guess)\n",
    "\n",
    "        if type(output) == list:\n",
    "            info = output\n",
    "        elif output == 2:\n",
    "            win = True\n",
    "\n",
    "        update_set = set([guess])\n",
    "        guessed.update(update_set)\n",
    "        unused = unused - update_set\n",
    "        unused_vowels = unused_vowels - update_set\n",
    "\n",
    "        vp = vowel_percentage(info)\n",
    "        \n",
    "        if (vp >= threshold):\n",
    "            unused = unused - set(unused_vowels)\n",
    "            guessed.update(set(unused_vowels))\n",
    "        \n",
    "        \n",
    "        n_lives = game.LIVES_LEFT\n",
    "        pattern = info2regex(info, unused)\n",
    "        matches = [word for word in matches if re.fullmatch(pattern, word)]\n",
    "\n",
    "    if win:\n",
    "        wins += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win Percentage on Validation Set: 0.502\n"
     ]
    }
   ],
   "source": [
    "print(f'Win Percentage on Validation Set: {wins / N_TRIALS}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hangman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
